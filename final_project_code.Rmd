---
title: "Approximate Bayesian Computation for Disease Outbreaks"
subtitle: "STAT S610"
author: "Elizabeth (Lizzy) Helms"
date: 'Due: 12/15/2020'
output:
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: 4
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '4'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      comment = NA, 
                      warning = FALSE, 
                      message = FALSE, 
                      fig.pos = 'H', 
                      fig.align = 'center', 
                      fig.height = 3, 
                      fig.width = 6, 
                      fig.dpi = 300)
library(ggplot2)
library(knitr)
library(dplyr)
library(testthat)
library(tidyverse)
```

\newpage

# Objectives and Framework

The goal of this project is to use Approximate Bayesian Computation to model 
disease outbreaks and answer the following questions: Can different outbreaks 
of the same strain and outbreaks of different molecular strains of the 
influenza virus be described by the same model of disease spread? To show this 
goal is accomplished, I will recreate Figures 3a and 3c from Tony and Stumpf, 
“Simulation based model selection for dynamical systems in systems and 
population biology”, Bioinformatics (2010).

ABC, as seen in the name, is rooted in Bayesian statistics, and is used to 
estimate the posterior distributions of model parameters. Theoretically, the 
steps of the process are as follows.

Given the prior distribution $P(\theta)$ of parameter $\theta$, the goal is to 
approximate the posterior distribution, $P(\theta | D_0) \propto f(D_0|\theta)P(\theta)$ 
where $f(D_0|\theta)$  is the likelihood of $\theta$ given the data $D_0$. We aim to 

(1) Sample a candidate parameter vector $\theta^*$ from prior distribution $P(\theta)$.

(2) Simulate a dataset $D^*$ from the model described by a conditional
probability distribution $f(D|\theta^*)$.

(3) Compare the simulated dataset, $D^*$, to the experimental data, $D_0$, using
a similarity measure, $d$, and tolerance $\epsilon$; if $d(D_0, D^*) \le \epsilon$, 
accept $\theta^*$. The tolerance $\epsilon \ge 0$ is the desired level of agreement 
between $D_0$ and $D^*$.

# Design Decisions and Methodology Implemented
## Data Setup
First, I need to setup the supplementary data provided from the 
paper as dataframes in R, so I can use them in the ABC simulation.

The columns of the dataframes represent the number of people in each household.
The rows represent out of those households, how many of the households had 
influenza in 1, 2, 3, 4, or 5 of the individuals.

Reproducing: Table 2: Influenza A ($H_3N_2$) infection in $1977-78$ (middle column) 
and $1980-1981$ (right column) epidemics, Tecumseh, Michigan [1].
```{r}
table_2_middle = 
  data.frame(matrix(c(
  66, 87, 25, 22, 4,
  13, 14, 15, 9, 4,
  0, 4, 4, 9, 1,
  0, 0, 4, 3, 1,
  0, 0, 0, 1, 1, 
  0, 0, 0, 0, 0), 
  ncol = 5, byrow = T))

table_2_right = 
  data.frame(matrix(c(
    44, 62, 47, 38, 9, 
    10, 13, 8, 11, 5,
    0, 9, 2, 7, 3, 
    0, 0, 3, 5, 1,
    0, 0, 0, 1, 0,
    0, 0, 0, 0, 1), 
    ncol = 5, byrow = T))

rownames(table_2_middle) = c("0 infected", "1 infected", "2 infected",
                             "3 infected", "4 infected", "5 infected")
colnames(table_2_middle) = c("1", "2", "3", "4", "5")
rownames(table_2_right) = c("0 infected", "1 infected", "2 infected",
                            "3 infected", "4 infected", "5 infected")
colnames(table_2_right) = c("1", "2", "3", "4", "5")
```

Reproducing: Table 3: Influenza B infection in $1975-76$ epidemic (middle column)
and influenza A ($H_1N_1$) infection in $1978-79$ epidemic (right column), Seattle, 
Washington [2].
```{r}
table_3_middle = 
  data.frame(matrix(c(
  9, 12, 18, 9, 4,
  1, 6, 6, 4, 3,
  0, 2, 3, 4, 0,
  0, 0, 1, 3, 2,
  0, 0, 0, 0, 0,
  0, 0, 0, 0, 0), 
  ncol = 5, byrow = T))

table_3_right = 
  data.frame(matrix(c(
   15, 12, 4, 0, 0,
   11, 17, 4, 0, 0, 
   0, 21, 4, 0, 0,
   0, 0, 5, 0, 0,
   0, 0, 0, 0, 0,
   0, 0, 0, 0, 0), 
   ncol = 5, byrow = T))

rownames(table_3_middle) = c("0 infected", "1 infected", "2 infected", 
                             "3 infected", "4 infected", "5 infected")
colnames(table_3_middle) = c("1", "2", "3", "4", "5")
rownames(table_3_right) = c("0 infected", "1 infected", "2 infected", 
                            "3 infected", "4 infected", "5 infected")
colnames(table_3_right) = c("1", "2", "3", "4", "5")
```

## Understanding of the parameters
The goal here is to compare the outbreak between the disease strains, and then
plot the  posterior distribution of four parameters. Each outbreak can be modeled
by two parameters, $q_c$ and $q_h$, where $q_c$ is the probability that a 
susceptible individual does NOT get infected from the community and $q_h$ is the
probability that a susceptible individual escapes infection in their OWN HOUSEHOLD. 

According to the source material paper, we connec the parameters to our data by 
defining $w_{js}$ as the probability that $j$ out of $s$ suspectible individuals in
a householde become infected, and is given by

$$w_{js} = {s \choose j}w_{jj}(q_cq_h^i)^{s-j}$$

where $w_{0s} = q_c^s$, $s = 0,1,2, \dots$ and $w_{jj} = 1 - \sum_{i=0}^{j-1}w_{ij}$.

With this knowledge, I adjusted my observed data to represent the proportions instead
of counts of the infected individuals.

```{r}
t2_mid = sweep(table_2_middle, 2, colSums(table_2_middle), "/")
t2_rig = sweep(table_2_right, 2, colSums(table_2_right), "/")
t3_mid = sweep(table_3_middle, 2, colSums(table_3_middle), "/")
t3_rig = sweep(table_3_right, 2, colSums(table_3_right), "/")

# t3_rig has some NaN because of dividing by 0, coercing those back to 0
t3_rig[,4:5] = 0
```

## Drawing parameters from a prior distribution

Prior distributions for all parameters were chosen to be uniform over the range
$[0, 1]$. 

```{r}
prior_dist_q = function() runif(n = 1, min = 0, max = 1)
```


## Generating data according to a probability model, given the parameters
A challenge I encountered while building this data generator 
was understanding $w_{jj}$. After writing out how it would be mathematically on
a whiteboard, I noticed that the process of generating rows of data must be 
iterative, since $w_{jj}$ depends on the previous row of data. For records sake,
the equations $w_{11}$ and $w_{55}$ are given below.

$w_{11} = 1 - \sum_{i=0}^{1-1} w_{i1} = 1 - w_{01}$

$w_{55} = 1 - \sum_{i=0}^{5-1} w_{i1} = 1 - \sum_{i=0}^{4} w_{i1} = 1 - (w_{05}+w_{15}+w_{25}+w_{35}+w_{45})$

```{r}
qh = runif(1, 0, 1)
# this is definitely hard-coded. I am working on trying to have a cleaner loop

generate_data = function(qh, qc) {
  # empty matrix, with row and column names to help me not get 
  # confused with indexing
  wjs = matrix(0, nrow = 6, ncol = 5)
  rownames(wjs) = c("0 infected", "1 infected", "2 infected", 
                             "3 infected", "4 infected", "5 infected")
  colnames(wjs) = c("1", "2", "3", "4", "5")
  
  # empty vector of wjj's
  wjj = rep(0, 6)
  
  # populate first row of wjs, j=0, w0s
  for (s in 1:5) {
    wjs[1,s] = qc^s
  }
    # generate w11
    wjj[1] = 1 - wjs[1,1]
    
    # 2nd row of wjs, j=1, w1s, 
    for (s in 1:5) {
      wjs[2,s] = choose(s, 1)*wjj[1]*(qc*qh^1)^(s - 1)
    }
    
    # generate w22
    wjj[2] = 1 - (wjs[1,2] + wjs[2,2])
    
    # 3rd row of wjs, j=2, w2s
    for (s in 1:5) {
      wjs[3,s] = choose(s, 2)*wjj[2]*(qc*qh^2)^(s - 2)
    }
    
    # generate w33
    wjj[3] = 1 - (wjs[1,3] + wjs[2,3] + wjs[3,3])
    
    # 4th row of wjs, j=3, w3s
    for (s in 1:5) {
      wjs[4,s] = choose(s, 3)*wjj[3]*(qc*qh^3)^(s - 3)
    }
    
    # generate w44
    wjj[4] = 1 - (wjs[1,4] + wjs[2,4] + wjs[3,4] + wjs[4,4])
    
    # 5th row of wjs, j=4, w4s
    for (s in 1:5) {
      wjs[5,s] = choose(s, 4)*wjj[4]*(qc*qh^4)^(s - 4)
    }
    
    # generate w55
    wjj[5] = 1 - (wjs[1,5] + wjs[2,5] + wjs[3,5] + wjs[4,5] + wjs[5,5])
    
    # 6th row of wjs, j=5, w5s
    for (s in 1:5) {
      wjs[6,s] = choose(s, 5)*wjj[5]*(qc*qh^5)^(s - 5)
    }
  return(wjs)
}

# q_c1 = prior_dist_q()
# q_h1 = prior_dist_q()
# generate_data(q_c1, q_h1)
```

## Computing a similarity measure between the simulated data and an observed dataset
In the source paper, the authors used the Frobenious norm as their similarity 
measure. I will be taking a simpler approach.

The similarity measure I'm using will be constructed with the summary statistic 
as the mean, since in a probabilistic sense this will produce what I need. I 
will compute the distance between the simulated mean and actual mean from 
observed data. Another candidate is the SSE, which I may test as well. 

Keeping or discarding the samples based on that similarity 

We said that if $x_{(i)}$ is the summary statistic resulting from
simulation i and $x_{(obs)}$ is the summary statistic for the observed data, 
we keep the parameter from simulation $i$ if 
$||x_{(i)} - x_{(obs)}|| \le \epsilon$

To examine how many households were surveyed in each scenario and
help determin my cutoffs for the ABC algorithm, similar to the HW
(i.e. what should $N*\epsilon$ be $\ge$ to, approximately?)


```{r}
N_vec = c(
  sum(table_2_middle, na.rm = T),
  sum(table_2_right, na.rm = T),
  sum(table_3_middle, na.rm = T),
  sum(table_3_right, na.rm = T))
N_vec
mean(c(N_vec[1], N_vec[2]))
```

For the Table 2 simulation, I want to retain approximately 283, or 300
observations.
```{r}
Goal = 300
epsilon = .1 # can vary
N = Goal/epsilon
N
```

```{r}
mean(c(N_vec[3], N_vec[4]))
```

For the Table 3 simulation, I want to retain approximately 90, or 100
observations.
```{r}
Goal = 100
epsilon = .1 # can vary
N = Goal/epsilon
N
```

## Construction of ABC sample framework 


```{r}

```

# Testing and Evidence

The nice thing about testing for this project is I have quite a clear end goal.
I need to reproduce plots of $q_c$ vs. $q_h$ from my posterior samples. In the 
four parameter model, this means a plot that has both $q_{c1}$ vs. $q_{h1}$ and
$q_{c2}$ vs. $q_{h2}$.

Testing if data generating function is working:
```{r}
# generate_data()
```

Testing simulation using ABC
```{r}
# abc_sample(observed_data = , prior_distribution = , data_generating_function = ,
  #         epsilon = , N = )
```


```{r}
# this does not run yet, but is the goal framework #
# this will be done twice, one for each comparison #
#post_plot_table_2 = 
 # data.frame(
  #qc1_post = posterior_samples[,1],
  #qc2_post = posterior_samples[,2],
  #qh1_post = posterior_samples[,3],
  #qh2_post = posterior_samples[,4])
#ggplot(post_plot_table_2) +
 # geom_point(aes(qh1_post, qc1_post, colour = "red")) +
#  geom_point(aes(qh2_post, qc2_post, colour = "blue")) +
 # xlab("q_h") + ylab("q_c") + xlim(c(0, 1)) + ylim(c(0,1))
```

Arbitrary plot simulation for presentation:
```{r}
# since I don't have simulated posteriors #
seq_test = seq(from = 0.5, to = 1, by = 0.01)
x1 = sample(seq_test, 100, replace = T)
y1 = sample(seq_test, 100, replace = T)

x2 = sample(seq_test, 100, replace = T)
y2 = sample(seq_test, 100, replace = T)

df_post_test1 = data.frame(x1, x2, y1, y2)

ggplot(df_post_test1) +
  geom_point(aes(x1, y1, colour = "red")) +
  geom_point(aes(x2, y2, colour = "blue")) +
  xlab("q_h") + ylab("q_c") + xlim(c(0, 1)) + ylim(c(0,1))

seq_test2 = seq(from = 0.3, to = 0.7, by = 0.01)
seq_test3 = seq(from = 0.4, to = 1, by = 0.01)
seq_test4 = seq(from = 0.75, to = 0.95, by = 0.01)

x3 = sample(seq_test3, 100, replace = T)
y3 = sample(seq_test2, 100, replace = T)

x4 = sample(seq_test4, 100, replace = T)
y4 = sample(seq_test4, 100, replace = T)

df_post_test2 = data.frame(x3, x4, y3, y4)

ggplot(df_post_test2) +
  geom_point(aes(x3, y3, colour = "red")) +
  geom_point(aes(x4, y4, colour = "blue")) +
  xlab("q_h") + ylab("q_c") + xlim(c(0, 1)) + ylim(c(0,1))
```


# Description

IT'S WORKINGGGG
